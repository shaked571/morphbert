{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current setup using this notebook\n",
    "<p>label - POS</p>\n",
    "<p>Fine tune on: raw-train</p>\n",
    "<p>Evaluate on: Raw-dev (and Raw-test, but not reported)</p>\n",
    "<p>Classification by: whole word (as opposed to prefix/host)</p>\n",
    "<p>Morphologically informed labels? None </p>\n",
    "<p>Shuffle/Sort? shuffle </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "import bclm\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "from transformers import BertForTokenClassification, AdamW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually setting seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(3)\n",
    "np.random.seed(3)\n",
    "torch.cuda.manual_seed_all(3)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "`bclm.read_dataframe('spmrl', subset='train')` - gives the gold-segmented tokens <br>\n",
    "`bclm.get_token_df(train, ['upostag'])` - gives the raw tokens<br>\n",
    "`bclm.read_dataframe('yap_dev')` - gives the YAP tokenization (only available on `yap_dev` and `yap_test`. No `yap_train`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = bclm.read_dataframe('spmrl', subset='train')\n",
    "train_df = bclm.get_token_df(train, ['upostag'])\n",
    "train_df['token_str'] = train_df['token_str'].str.replace('”','\"')\n",
    "\n",
    "dev = bclm.read_dataframe('spmrl', subset='dev')\n",
    "dev_df = bclm.get_token_df(dev, ['upostag'])\n",
    "dev_df['token_str'] = dev_df['token_str'].str.replace('”','\"')\n",
    "\n",
    "test = bclm.read_dataframe('spmrl', subset='test')\n",
    "test_df = bclm.get_token_df(test, ['upostag'])\n",
    "test_df['token_str'] = test_df['token_str'].str.replace('”','\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token_str</th>\n",
       "      <th>upostag</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>עשרות</td>\n",
       "      <td>CDT</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>אנשים</td>\n",
       "      <td>NN</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>מגיעים</td>\n",
       "      <td>BN</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>PREPOSITION^NNP</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>לישראל</td>\n",
       "      <td>PREPOSITION^NNP</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>כשהם</td>\n",
       "      <td>TEMP^PRP</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>נרשמים</td>\n",
       "      <td>BN</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>כמתנדבים</td>\n",
       "      <td>PREPOSITION^NN</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>,</td>\n",
       "      <td>yyCM</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>אך</td>\n",
       "      <td>CC</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>למעשה</td>\n",
       "      <td>RB</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>משמשים</td>\n",
       "      <td>BN</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>עובדים</td>\n",
       "      <td>NN</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>שכירים</td>\n",
       "      <td>JJ</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>זולים</td>\n",
       "      <td>JJ</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>.</td>\n",
       "      <td>yyDOT</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>תופעה</td>\n",
       "      <td>NN</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>זו</td>\n",
       "      <td>PRP</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>התבררה</td>\n",
       "      <td>VB</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>אתמול</td>\n",
       "      <td>RB</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sent_id  token_id token_str          upostag  set\n",
       "0         1         1     עשרות              CDT  dev\n",
       "1         1         2     אנשים               NN  dev\n",
       "2         1         3    מגיעים               BN  dev\n",
       "3         1         4   מתאילנד  PREPOSITION^NNP  dev\n",
       "4         1         5    לישראל  PREPOSITION^NNP  dev\n",
       "5         1         6      כשהם         TEMP^PRP  dev\n",
       "6         1         7    נרשמים               BN  dev\n",
       "7         1         8  כמתנדבים   PREPOSITION^NN  dev\n",
       "8         1         9         ,             yyCM  dev\n",
       "9         1        10        אך               CC  dev\n",
       "10        1        11     למעשה               RB  dev\n",
       "11        1        12    משמשים               BN  dev\n",
       "12        1        13    עובדים               NN  dev\n",
       "13        1        14    שכירים               JJ  dev\n",
       "14        1        15     זולים               JJ  dev\n",
       "15        1        16         .            yyDOT  dev\n",
       "16        2         1     תופעה               NN  dev\n",
       "17        2         2        זו              PRP  dev\n",
       "18        2         3    התבררה               VB  dev\n",
       "19        2         4     אתמול               RB  dev"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform column names\n",
    "Note that the column names in yap dfs can be slightly different from spmrl dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Evaluating on Raw-dev/Raw-test\n",
    "train_df.rename(columns = {\"token_str\": \"form\"}, inplace = True)\n",
    "dev_df.rename(columns = {\"token_str\": \"form\"}, inplace = True)\n",
    "test_df.rename(columns = {\"token_str\": \"form\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For Evaluating on Yap-dev/Yap-test\n",
    "# dev_df.rename(columns = {\"misc_token_id\": \"token_id\"}, inplace = True)\n",
    "# test_df.rename(columns = {\"misc_token_id\": \"token_id\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>form</th>\n",
       "      <th>upostag</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>עשרות</td>\n",
       "      <td>CDT</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>אנשים</td>\n",
       "      <td>NN</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>מגיעים</td>\n",
       "      <td>BN</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>PREPOSITION^NNP</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>לישראל</td>\n",
       "      <td>PREPOSITION^NNP</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>כשהם</td>\n",
       "      <td>TEMP^PRP</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>נרשמים</td>\n",
       "      <td>BN</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>כמתנדבים</td>\n",
       "      <td>PREPOSITION^NN</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>,</td>\n",
       "      <td>yyCM</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>אך</td>\n",
       "      <td>CC</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sent_id  token_id      form          upostag  set\n",
       "0        1         1     עשרות              CDT  dev\n",
       "1        1         2     אנשים               NN  dev\n",
       "2        1         3    מגיעים               BN  dev\n",
       "3        1         4   מתאילנד  PREPOSITION^NNP  dev\n",
       "4        1         5    לישראל  PREPOSITION^NNP  dev\n",
       "5        1         6      כשהם         TEMP^PRP  dev\n",
       "6        1         7    נרשמים               BN  dev\n",
       "7        1         8  כמתנדבים   PREPOSITION^NN  dev\n",
       "8        1         9         ,             yyCM  dev\n",
       "9        1        10        אך               CC  dev"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Number of gpus: 4\n",
      "Name of gpu: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "print(\"Device: \" + str(device))\n",
    "print(\"Number of gpus: \" + str(n_gpu))\n",
    "print(\"Name of gpu: \" + torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Add sorting on the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sent_id\n",
       "4226     1\n",
       "611      2\n",
       "949      2\n",
       "1671     2\n",
       "2466     2\n",
       "        ..\n",
       "3862    71\n",
       "1756    72\n",
       "2973    75\n",
       "4116    75\n",
       "1816    80\n",
       "Length: 4937, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['sent_len'] = train_df.groupby('sent_id').sent_id.transform('size')\n",
    "s = train_df.sort_values(by=['sent_len', 'sent_id']).index\n",
    "train_df_sorted = train_df.reindex(s)\n",
    "train_df_sorted.groupby('sent_id', sort=False).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>form</th>\n",
       "      <th>upostag</th>\n",
       "      <th>set</th>\n",
       "      <th>sent_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38277</th>\n",
       "      <td>2426</td>\n",
       "      <td>4</td>\n",
       "      <td>.</td>\n",
       "      <td>yyDOT</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38562</th>\n",
       "      <td>2457</td>\n",
       "      <td>1</td>\n",
       "      <td>הפסקנו</td>\n",
       "      <td>VB</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38563</th>\n",
       "      <td>2457</td>\n",
       "      <td>2</td>\n",
       "      <td>מחנות</td>\n",
       "      <td>NNT</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38564</th>\n",
       "      <td>2457</td>\n",
       "      <td>3</td>\n",
       "      <td>אימונים</td>\n",
       "      <td>NN</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38565</th>\n",
       "      <td>2457</td>\n",
       "      <td>4</td>\n",
       "      <td>.</td>\n",
       "      <td>yyDOT</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38566</th>\n",
       "      <td>2458</td>\n",
       "      <td>1</td>\n",
       "      <td>הפסקנו</td>\n",
       "      <td>VB</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38567</th>\n",
       "      <td>2458</td>\n",
       "      <td>2</td>\n",
       "      <td>תשלום</td>\n",
       "      <td>NN</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38568</th>\n",
       "      <td>2458</td>\n",
       "      <td>3</td>\n",
       "      <td>למאמנים</td>\n",
       "      <td>PREPOSITION^DEF^NN</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38569</th>\n",
       "      <td>2458</td>\n",
       "      <td>4</td>\n",
       "      <td>.</td>\n",
       "      <td>yyDOT</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38570</th>\n",
       "      <td>2459</td>\n",
       "      <td>1</td>\n",
       "      <td>הענפים</td>\n",
       "      <td>DEF^NN</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38571</th>\n",
       "      <td>2459</td>\n",
       "      <td>2</td>\n",
       "      <td>לא</td>\n",
       "      <td>RB</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38572</th>\n",
       "      <td>2459</td>\n",
       "      <td>3</td>\n",
       "      <td>חרגו</td>\n",
       "      <td>VB</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38573</th>\n",
       "      <td>2459</td>\n",
       "      <td>4</td>\n",
       "      <td>.</td>\n",
       "      <td>yyDOT</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38644</th>\n",
       "      <td>2467</td>\n",
       "      <td>1</td>\n",
       "      <td>אין</td>\n",
       "      <td>EX</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38645</th>\n",
       "      <td>2467</td>\n",
       "      <td>2</td>\n",
       "      <td>לנו</td>\n",
       "      <td>IN^S_PRN</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38646</th>\n",
       "      <td>2467</td>\n",
       "      <td>3</td>\n",
       "      <td>כסף</td>\n",
       "      <td>NN</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38647</th>\n",
       "      <td>2467</td>\n",
       "      <td>4</td>\n",
       "      <td>.</td>\n",
       "      <td>yyDOT</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38648</th>\n",
       "      <td>2468</td>\n",
       "      <td>1</td>\n",
       "      <td>נעבוד</td>\n",
       "      <td>VB</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38649</th>\n",
       "      <td>2468</td>\n",
       "      <td>2</td>\n",
       "      <td>באותה</td>\n",
       "      <td>PREPOSITION^DT</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38650</th>\n",
       "      <td>2468</td>\n",
       "      <td>3</td>\n",
       "      <td>מתכונת</td>\n",
       "      <td>NN</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38651</th>\n",
       "      <td>2468</td>\n",
       "      <td>4</td>\n",
       "      <td>.</td>\n",
       "      <td>yyDOT</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38757</th>\n",
       "      <td>2479</td>\n",
       "      <td>1</td>\n",
       "      <td>הכניסה</td>\n",
       "      <td>DEF^NN</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38758</th>\n",
       "      <td>2479</td>\n",
       "      <td>2</td>\n",
       "      <td>לאירופה</td>\n",
       "      <td>PREPOSITION^NNP</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38759</th>\n",
       "      <td>2479</td>\n",
       "      <td>3</td>\n",
       "      <td>נפלאה</td>\n",
       "      <td>JJ</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38760</th>\n",
       "      <td>2479</td>\n",
       "      <td>4</td>\n",
       "      <td>.</td>\n",
       "      <td>yyDOT</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38912</th>\n",
       "      <td>2492</td>\n",
       "      <td>1</td>\n",
       "      <td>זו</td>\n",
       "      <td>PRP</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38913</th>\n",
       "      <td>2492</td>\n",
       "      <td>2</td>\n",
       "      <td>בדיקה</td>\n",
       "      <td>NN</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38914</th>\n",
       "      <td>2492</td>\n",
       "      <td>3</td>\n",
       "      <td>אובייקטיווית</td>\n",
       "      <td>JJ</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38915</th>\n",
       "      <td>2492</td>\n",
       "      <td>4</td>\n",
       "      <td>.</td>\n",
       "      <td>yyDOT</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38977</th>\n",
       "      <td>2501</td>\n",
       "      <td>1</td>\n",
       "      <td>שיט</td>\n",
       "      <td>NN</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38978</th>\n",
       "      <td>2501</td>\n",
       "      <td>2</td>\n",
       "      <td>,</td>\n",
       "      <td>yyCM</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38979</th>\n",
       "      <td>2501</td>\n",
       "      <td>3</td>\n",
       "      <td>למשל</td>\n",
       "      <td>CC</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38980</th>\n",
       "      <td>2501</td>\n",
       "      <td>4</td>\n",
       "      <td>.</td>\n",
       "      <td>yyDOT</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39059</th>\n",
       "      <td>2507</td>\n",
       "      <td>1</td>\n",
       "      <td>התחרות</td>\n",
       "      <td>DEF^NN</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39060</th>\n",
       "      <td>2507</td>\n",
       "      <td>2</td>\n",
       "      <td>היתה</td>\n",
       "      <td>COP</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39061</th>\n",
       "      <td>2507</td>\n",
       "      <td>3</td>\n",
       "      <td>בהרצליה</td>\n",
       "      <td>PREPOSITION^NNP</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39062</th>\n",
       "      <td>2507</td>\n",
       "      <td>4</td>\n",
       "      <td>.</td>\n",
       "      <td>yyDOT</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>2561</td>\n",
       "      <td>1</td>\n",
       "      <td>קישור</td>\n",
       "      <td>NN</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>2561</td>\n",
       "      <td>2</td>\n",
       "      <td>עדיין</td>\n",
       "      <td>RB</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>2561</td>\n",
       "      <td>3</td>\n",
       "      <td>מקרטע</td>\n",
       "      <td>BN</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>2561</td>\n",
       "      <td>4</td>\n",
       "      <td>.</td>\n",
       "      <td>yyDOT</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40481</th>\n",
       "      <td>2593</td>\n",
       "      <td>1</td>\n",
       "      <td>התחרויות</td>\n",
       "      <td>DEF^NN</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40482</th>\n",
       "      <td>2593</td>\n",
       "      <td>2</td>\n",
       "      <td>היו</td>\n",
       "      <td>COP</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40483</th>\n",
       "      <td>2593</td>\n",
       "      <td>3</td>\n",
       "      <td>בוינגייט</td>\n",
       "      <td>PREPOSITION^NNP</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40484</th>\n",
       "      <td>2593</td>\n",
       "      <td>4</td>\n",
       "      <td>.</td>\n",
       "      <td>yyDOT</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41345</th>\n",
       "      <td>2643</td>\n",
       "      <td>1</td>\n",
       "      <td>מהשלוש</td>\n",
       "      <td>PREPOSITION^DEF^CD</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41346</th>\n",
       "      <td>2643</td>\n",
       "      <td>2</td>\n",
       "      <td>תצא</td>\n",
       "      <td>VB</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41347</th>\n",
       "      <td>2643</td>\n",
       "      <td>3</td>\n",
       "      <td>אחת</td>\n",
       "      <td>CD</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41348</th>\n",
       "      <td>2643</td>\n",
       "      <td>4</td>\n",
       "      <td>.</td>\n",
       "      <td>yyDOT</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43482</th>\n",
       "      <td>2744</td>\n",
       "      <td>1</td>\n",
       "      <td>גילרדי</td>\n",
       "      <td>NNP</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sent_id  token_id          form             upostag    set  sent_len\n",
       "38277     2426         4             .               yyDOT  train         4\n",
       "38562     2457         1        הפסקנו                  VB  train         4\n",
       "38563     2457         2         מחנות                 NNT  train         4\n",
       "38564     2457         3       אימונים                  NN  train         4\n",
       "38565     2457         4             .               yyDOT  train         4\n",
       "38566     2458         1        הפסקנו                  VB  train         4\n",
       "38567     2458         2         תשלום                  NN  train         4\n",
       "38568     2458         3       למאמנים  PREPOSITION^DEF^NN  train         4\n",
       "38569     2458         4             .               yyDOT  train         4\n",
       "38570     2459         1        הענפים              DEF^NN  train         4\n",
       "38571     2459         2            לא                  RB  train         4\n",
       "38572     2459         3          חרגו                  VB  train         4\n",
       "38573     2459         4             .               yyDOT  train         4\n",
       "38644     2467         1           אין                  EX  train         4\n",
       "38645     2467         2           לנו            IN^S_PRN  train         4\n",
       "38646     2467         3           כסף                  NN  train         4\n",
       "38647     2467         4             .               yyDOT  train         4\n",
       "38648     2468         1         נעבוד                  VB  train         4\n",
       "38649     2468         2         באותה      PREPOSITION^DT  train         4\n",
       "38650     2468         3        מתכונת                  NN  train         4\n",
       "38651     2468         4             .               yyDOT  train         4\n",
       "38757     2479         1        הכניסה              DEF^NN  train         4\n",
       "38758     2479         2       לאירופה     PREPOSITION^NNP  train         4\n",
       "38759     2479         3         נפלאה                  JJ  train         4\n",
       "38760     2479         4             .               yyDOT  train         4\n",
       "38912     2492         1            זו                 PRP  train         4\n",
       "38913     2492         2         בדיקה                  NN  train         4\n",
       "38914     2492         3  אובייקטיווית                  JJ  train         4\n",
       "38915     2492         4             .               yyDOT  train         4\n",
       "38977     2501         1           שיט                  NN  train         4\n",
       "38978     2501         2             ,                yyCM  train         4\n",
       "38979     2501         3          למשל                  CC  train         4\n",
       "38980     2501         4             .               yyDOT  train         4\n",
       "39059     2507         1        התחרות              DEF^NN  train         4\n",
       "39060     2507         2          היתה                 COP  train         4\n",
       "39061     2507         3       בהרצליה     PREPOSITION^NNP  train         4\n",
       "39062     2507         4             .               yyDOT  train         4\n",
       "39995     2561         1         קישור                  NN  train         4\n",
       "39996     2561         2         עדיין                  RB  train         4\n",
       "39997     2561         3         מקרטע                  BN  train         4\n",
       "39998     2561         4             .               yyDOT  train         4\n",
       "40481     2593         1      התחרויות              DEF^NN  train         4\n",
       "40482     2593         2           היו                 COP  train         4\n",
       "40483     2593         3      בוינגייט     PREPOSITION^NNP  train         4\n",
       "40484     2593         4             .               yyDOT  train         4\n",
       "41345     2643         1        מהשלוש  PREPOSITION^DEF^CD  train         4\n",
       "41346     2643         2           תצא                  VB  train         4\n",
       "41347     2643         3           אחת                  CD  train         4\n",
       "41348     2643         4             .               yyDOT  train         4\n",
       "43482     2744         1        גילרדי                 NNP  train         4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_sorted.iloc[150:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get lists of sentences\n",
    "Note that longest sentences from dev and test splits need to be removed, and those sentences change depending on wether or not sorting was applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['אדם', 'נהרג', ',', 'אדם', 'נרצח', 'בידי', 'רעולי', 'פנים', 'ואחר', 'נדקר', 'על', 'ידם', ',', '308', 'נפצעו', ',', 'לפי', 'מקורות', 'פלשתיניים', ',', 'וכן', 'נפצעו', 'שישה', 'חיילי', 'צה\"ל', 'ותיירת', 'אחת', 'באירועי', 'השבוע', 'בשטחים', '.']\n",
      "['NN', 'VB', 'yyCM', 'NN', 'VB', 'IN', 'JJT', 'NN', 'CONJ^JJ', 'VB', 'IN', 'NN', 'yyCM', 'CD', 'VB', 'yyCM', 'IN', 'NN', 'JJ', 'yyCM', 'CONJ^RB', 'VB', 'CD', 'NNT', 'NNP', 'CONJ^NN', 'CD', 'PREPOSITION^NNT', 'DEF^NN', 'PREPOSITION^DEF^NN', 'yyDOT']\n",
      "490\n",
      "712\n"
     ]
    }
   ],
   "source": [
    "class sentenceGetter(object):\n",
    "    def __init__(self, data, max_sent=None):\n",
    "        self.index = 0\n",
    "        self.max_sent = max_sent\n",
    "        self.tokens = data['form']\n",
    "        self.labels = data['upostag']\n",
    "        #for evaluating by word-accuracy\n",
    "        self.correspondingToken = data['token_id']\n",
    "        self.orig_sent_id = data['sent_id']\n",
    "    \n",
    "    def sentences(self):\n",
    "        sent = []\n",
    "        counter = 0\n",
    "        \n",
    "        for token,label, corres_tok, sent_id in zip(self.tokens, self.labels, self.correspondingToken, self.orig_sent_id):\n",
    "            sent.append((token, label, corres_tok, sent_id))\n",
    "            if token.strip() == \".\":\n",
    "                yield sent\n",
    "                sent = []\n",
    "                counter += 1\n",
    "            if self.max_sent is not None and counter >= self.max_sent:\n",
    "                return\n",
    "\n",
    "train_getter = sentenceGetter(train_df)\n",
    "dev_getter = sentenceGetter(dev_df)\n",
    "test_getter = sentenceGetter(test_df)\n",
    "\n",
    "train_sentences = [[token for token, label, corres_tok, sent_id in sent] for sent in train_getter.sentences()]\n",
    "train_labels = [[label for token, label, corres_tok, sent_id in sent] for sent in train_getter.sentences()]\n",
    "\n",
    "dev_sentences = [[token for token, label, corres_tok, sent_id in sent] for sent in dev_getter.sentences()]\n",
    "dev_labels = [[label for token, label, corres_tok, sent_id in sent] for sent in dev_getter.sentences()]\n",
    "dev_corresTokens = [[corres_tok for token, label, corres_tok, sent_id in sent] for sent in dev_getter.sentences()]\n",
    "dev_sent_ids = [[sent_id for token, label, corres_tok, sent_id in sent] for sent in dev_getter.sentences()]\n",
    "\n",
    "test_sentences = [[token for token, label, corres_tok, sent_id in sent] for sent in test_getter.sentences()]\n",
    "test_labels = [[label for token, label, corres_tok, sent_id in sent] for sent in test_getter.sentences()]\n",
    "test_corresTokens = [[corres_tok for token, label, corres_tok, sent_id in sent] for sent in test_getter.sentences()]\n",
    "test_sent_ids = [[sent_id for token, label, corres_tok, sent_id in sent] for sent in test_getter.sentences()]\n",
    "\n",
    "print(train_sentences[11])\n",
    "print(train_labels[11])\n",
    "\n",
    "print(len(dev_sentences))\n",
    "print(len(test_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "index of longest sentence:0 \n",
      "16\n",
      "index of longest sentence:1 \n",
      "31\n",
      "index of longest sentence:2 \n",
      "32\n",
      "index of longest sentence:9 \n",
      "36\n",
      "index of longest sentence:24 \n",
      "54\n",
      "index of longest sentence:49 \n",
      "57\n",
      "index of longest sentence:57 \n",
      "59\n",
      "index of longest sentence:226 \n",
      "76\n",
      "index of longest sentence:296 \n",
      "11\n",
      "index of longest sentence:0 \n",
      "24\n",
      "index of longest sentence:1 \n",
      "25\n",
      "index of longest sentence:27 \n",
      "32\n",
      "index of longest sentence:29 \n",
      "32\n",
      "index of longest sentence:33 \n",
      "35\n",
      "index of longest sentence:42 \n",
      "40\n",
      "index of longest sentence:104 \n",
      "42\n",
      "index of longest sentence:151 \n",
      "43\n",
      "index of longest sentence:157 \n",
      "52\n",
      "index of longest sentence:164 \n",
      "61\n",
      "index of longest sentence:396 \n"
     ]
    }
   ],
   "source": [
    "## Get the longest sentences in the dev and test sets\n",
    "longest_sent_len = 0\n",
    "for sent in dev_sentences:\n",
    "    if len(sent) >= longest_sent_len:\n",
    "        print(len(sent))\n",
    "        longest_sent_len = len(sent)\n",
    "        print(\"index of longest sentence:{} \".format(dev_sentences.index(sent)))\n",
    "        \n",
    "longest_sent_len = 0\n",
    "for sent in test_sentences:\n",
    "    if len(sent) >= longest_sent_len:\n",
    "        print(len(sent))\n",
    "        longest_sent_len = len(sent)\n",
    "        print(\"index of longest sentence:{} \".format(test_sentences.index(sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove too long sentences\n",
    "\n",
    "del dev_sentences[296]\n",
    "del dev_labels[296]\n",
    "del dev_corresTokens[296]\n",
    "del dev_sent_ids[296]\n",
    "\n",
    "del dev_sentences[226]\n",
    "del dev_labels[226]\n",
    "del dev_corresTokens[226]\n",
    "del dev_sent_ids[226]\n",
    "\n",
    "del dev_sentences[57]\n",
    "del dev_labels[57]\n",
    "del dev_corresTokens[57]\n",
    "del dev_sent_ids[57]\n",
    "\n",
    "del dev_sentences[49]\n",
    "del dev_labels[49]\n",
    "del dev_corresTokens[49]\n",
    "del dev_sent_ids[49]\n",
    "\n",
    "\n",
    "del test_sentences[396]\n",
    "del test_labels[396]\n",
    "del test_corresTokens[396]\n",
    "del test_sent_ids[396]\n",
    "\n",
    "del test_sentences[164]\n",
    "del test_labels[164]\n",
    "del test_corresTokens[164]\n",
    "del test_sent_ids[164]\n",
    "\n",
    "del test_sentences[157]\n",
    "del test_labels[157]\n",
    "del test_corresTokens[157]\n",
    "del test_sent_ids[157]\n",
    "\n",
    "del test_sentences[151]\n",
    "del test_labels[151]\n",
    "del test_corresTokens[151]\n",
    "del test_sent_ids[151]\n",
    "\n",
    "# ## YAP deletions\n",
    "# del dev_sentences[296]\n",
    "# del dev_labels[296]\n",
    "# del dev_corresTokens[296]\n",
    "# del dev_sent_ids[296]\n",
    "\n",
    "# del dev_sentences[226]\n",
    "# del dev_labels[226]\n",
    "# del dev_corresTokens[226]\n",
    "# del dev_sent_ids[226]\n",
    "\n",
    "# del dev_sentences[57]\n",
    "# del dev_labels[57]\n",
    "# del dev_corresTokens[57]\n",
    "# del dev_sent_ids[57]\n",
    "\n",
    "# del dev_sentences[49]\n",
    "# del dev_labels[49]\n",
    "# del dev_corresTokens[49]\n",
    "# del dev_sent_ids[49]\n",
    "\n",
    "# del dev_sentences[24]\n",
    "# del dev_labels[24]\n",
    "# del dev_corresTokens[24]\n",
    "# del dev_sent_ids[24]\n",
    "\n",
    "# del dev_sentences[22]\n",
    "# del dev_labels[22]\n",
    "# del dev_corresTokens[22]\n",
    "# del dev_sent_ids[22]\n",
    "\n",
    "# del dev_sentences[12]\n",
    "# del dev_labels[12]\n",
    "# del dev_corresTokens[12]\n",
    "# del dev_sent_ids[12]\n",
    "\n",
    "# del dev_sentences[9]\n",
    "# del dev_labels[9]\n",
    "# del dev_corresTokens[9]\n",
    "# del dev_sent_ids[9]\n",
    "\n",
    "# del dev_sentences[5]\n",
    "# del dev_labels[5]\n",
    "# del dev_corresTokens[5]\n",
    "# del dev_sent_ids[5]\n",
    "\n",
    "# del test_sentences[386]\n",
    "# del test_labels[386]\n",
    "# del test_corresTokens[386]\n",
    "# del test_sent_ids[386]\n",
    "\n",
    "# del test_sentences[384]\n",
    "# del test_labels[384]\n",
    "# del test_corresTokens[384]\n",
    "# del test_sent_ids[384]\n",
    "\n",
    "# del test_sentences[377]\n",
    "# del test_labels[377]\n",
    "# del test_corresTokens[377]\n",
    "# del test_sent_ids[377]\n",
    "\n",
    "# del test_sentences[213]\n",
    "# del test_labels[213]\n",
    "# del test_corresTokens[213]\n",
    "# del test_sent_ids[213]\n",
    "\n",
    "# del test_sentences[141]\n",
    "# del test_labels[141]\n",
    "# del test_corresTokens[141]\n",
    "# del test_sent_ids[141]\n",
    "\n",
    "# del test_sentences[124]\n",
    "# del test_labels[124]\n",
    "# del test_corresTokens[124]\n",
    "# del test_sent_ids[124]\n",
    "\n",
    "# del test_sentences[45]\n",
    "# del test_labels[45]\n",
    "# del test_corresTokens[45]\n",
    "# del test_sent_ids[45]\n",
    "\n",
    "# del test_sentences[35]\n",
    "# del test_labels[35]\n",
    "# del test_corresTokens[35]\n",
    "# del test_sent_ids[35]\n",
    "\n",
    "# del test_sentences[23]\n",
    "# del test_labels[23]\n",
    "# del test_corresTokens[23]\n",
    "# del test_sent_ids[23]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Number of gpus: 4\n",
      "Name of gpu: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "print(\"Device: \" + str(device))\n",
    "print(\"Number of gpus: \" + str(n_gpu))\n",
    "print(\"Name of gpu: \" + torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 150\n",
    "bs = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['הם', 'ה', '##ת', '##בק', '##שו', 'ל', '##דו', '##וח', 'ל', '##משטרה', 'על', 'ת', '##נוע', '##ות', '##יהם', '.']\n",
      "['PRP', 'VB', 'VB', 'VB', 'VB', 'VB', 'VB', 'VB', 'PREPOSITION^DEF^NN', 'PREPOSITION^DEF^NN', 'IN', 'NN', 'NN', 'NN', 'NN', 'yyDOT']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
    "def tokenize(sentences, orig_labels):\n",
    "    tokenized_texts = []\n",
    "    labels = []\n",
    "    for sent, sent_labels in zip(sentences, orig_labels):\n",
    "        bert_tokens = []\n",
    "        bert_labels = []\n",
    "        for orig_token, orig_label in zip(sent, sent_labels):\n",
    "            b_tokens = tokenizer.tokenize(orig_token)\n",
    "            bert_tokens.extend(b_tokens)\n",
    "            for b_token in b_tokens:\n",
    "                bert_labels.append(orig_label)\n",
    "        tokenized_texts.append(bert_tokens)\n",
    "        labels.append(bert_labels)\n",
    "        assert len(bert_tokens) == len(bert_labels)\n",
    "    return tokenized_texts, labels\n",
    "\n",
    "train_tokenized_texts, train_tokenized_labels = tokenize(train_sentences, train_labels)\n",
    "print(train_tokenized_texts[10])\n",
    "print(train_tokenized_labels[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PAD': 0, 'REL^yyQUOT^VB': 1, 'PRP': 2, 'TEMP^PREPOSITION^PRP': 3, 'CONJ^REL^DEF^NN': 4, 'REL^IN^PRP': 5, 'REL^CDT': 6, 'NCD': 7, 'TEMP^RB': 8, 'TEMP^NNP': 9, 'ZVL^IN': 10, 'CONJ^BN^AT^PRP': 11, 'PREPOSITION^IN': 12, 'DEF^yyQUOT^JJ': 13, 'PREPOSITION^DT': 14, 'CONJ^DEF^JJ': 15, 'REL^RB': 16, 'IN^PRP': 17, 'REL^yyQUOT^DEF^NN': 18, 'PREPOSITION^DTT': 19, 'TEMP^DEF^CD': 20, 'COP': 21, 'REL^NNP': 22, 'PREPOSITION^PREPOSITION^NNT': 23, 'ADVERB^DTT': 24, 'ZVL^ZVL': 25, 'CONJ^PREPOSITION^NNT': 26, 'ZVL^PREPOSITION^NN': 27, 'CONJ^PREPOSITION^CDT': 28, 'yySCLN': 29, 'CONJ^yyQUOT^NNP': 30, 'REL^DEF^CD': 31, 'PREPOSITION^PRP': 32, 'IN^REL^NNT': 33, 'CONJ^IN': 34, 'REL^PREPOSITION^BN': 35, 'CONJ^REL^EX': 36, 'DEF^COP': 37, 'CONJ^CD': 38, 'PREPOSITION^REL^COP': 39, 'REL^IN': 40, 'PREPOSITION^ADVERB^NN': 41, 'DEF^DEF^NN': 42, 'CONJ^IN^S_PRN': 43, 'CONJ^DEF^BN': 44, 'PREPOSITION^yyQUOT^NNT': 45, 'ZVL^JJT': 46, 'CONJ^IN^JJT': 47, 'ZVL^NNP': 48, 'POS^S_PRN': 49, 'CONJ^REL^PREPOSITION^NN': 50, 'POS': 51, 'REL^PREPOSITION^DT': 52, 'CONJ^PREPOSITION^JJ': 53, 'PREPOSITION^DEF^CDT': 54, 'DEF^CD': 55, 'yyQUOT': 56, 'PREPOSITION^REL^VB': 57, 'PREPOSITION^DEF^CD': 58, 'PREPOSITION^NNP': 59, 'CONJ^PREPOSITION^PRP': 60, 'TEMP^IN': 61, 'CONJ^MD': 62, 'PREPOSITION^ADVERB^NCD': 63, 'REL^PREPOSITION^DEF^NN': 64, 'REL^NN': 65, 'PREPOSITION^PREPOSITION^DEF^PRP': 66, 'CONJ^REL^IN': 67, 'DEF^P': 68, 'DEF^NNP': 69, 'PREPOSITION^PREPOSITION^DEF^NN': 70, 'CONJ^PREPOSITION^yyQUOT^CDT': 71, 'CONJ^DEF^yyQUOT^NN': 72, 'PREPOSITION^JJ': 73, 'JJT': 74, 'yyEXCL': 75, 'PREPOSITION^ADVERB^CD': 76, 'REL^DT': 77, 'REL^MD': 78, 'REL^VB': 79, 'REL^PREPOSITION^yyQUOT^NNP': 80, 'PREPOSITION^CDT': 81, 'yyELPS': 82, 'ZVL^CD': 83, 'PREPOSITION^POS^S_PRN': 84, 'CONJ^PREPOSITION^NN': 85, 'CONJ^PREPOSITION^QW': 86, 'PREPOSITION^NNT': 87, 'IN^IN': 88, 'PREPOSITIONIN^PREPOSITION^NN': 89, 'PREPOSITION^NCD': 90, 'IN^NCD': 91, 'ZVL^NN': 92, 'REL^CD': 93, 'yyLRB': 94, 'RB^S_PRN': 95, 'REL^COP': 96, 'TEMP^COP': 97, 'IN': 98, 'CONJ^COP': 99, 'REL^DEF^BN': 100, 'PREPOSITION^QW': 101, 'IN^S_PRN': 102, 'CONJ^REL^VB': 103, 'BNT': 104, 'CONJ^CC': 105, 'PREPOSITION^DEF^PRP': 106, 'REL^yyQUOT^MD': 107, 'IN^DEF^NN': 108, 'DEF^JJ': 109, 'REL^CC': 110, 'PREPOSITION^DEF^BN': 111, 'PREPOSITION^yyQUOT^DEF^NN': 112, 'CC^ZVL^DEF^NN': 113, 'REL^PREPOSITION^NNP': 114, 'CONJ^DT': 115, 'TEMP^DEF^NN': 116, 'CDT': 117, 'VB': 118, 'PREPOSITION^yyQUOT^PREPOSITION^NNT': 119, 'TEMP^PRP': 120, 'PREPOSITION': 121, 'CONJ^yyQUOT^IN': 122, 'DEF^BN^AT^PRP': 123, 'P^NN': 124, 'PREPOSITION^P': 125, 'ZVL^DEF^NN': 126, 'NEG': 127, 'IN^DTT': 128, 'TEMP^PREPOSITION^NN': 129, 'DEF^PREPOSITION^NNT': 130, 'REL^NNT': 131, 'IN^NNT': 132, 'MD': 133, 'CONJ^PREPOSITION^BNT': 134, 'REL^P': 135, 'REL^JJT': 136, 'CONJ^DEF^P': 137, 'PREPOSITION^BN': 138, 'PREPOSITION^DEF^NNP': 139, 'REL^PREPOSITION^NNT': 140, 'EX': 141, 'PREPOSITION^PREPOSITION^NN': 142, 'NNP': 143, 'REL^DTT': 144, 'CONJ^PREPOSITION^P': 145, 'IN^IN^NNT': 146, 'REL^PREPOSITION^RB': 147, 'CONJ^PREPOSITION^DEF^CD': 148, 'NN': 149, 'CONJ^POS': 150, 'PREPOSITION^IN^S_PRN': 151, 'CONJ^PREPOSITION^CC': 152, 'CONJ^VB^AT^PRP': 153, 'REL^AT': 154, 'CC': 155, 'TEMP^VB': 156, 'CONJ^PREPOSITION^DEF^PRP': 157, 'REL^yyQUOT^COP': 158, 'TEMP^DEF^BN': 159, 'CONJ^TEMP^BN': 160, 'PREPOSITION^DEF^yyQUOT^NNP': 161, 'ZVL^PREPOSITION^DEF^NN': 162, 'CONJ^DTT': 163, 'ADVERB^CD': 164, 'REL^JJ': 165, 'CONJ^NNP': 166, 'ZVL^DEF^NNP': 167, 'CONJ^DEF^NNP': 168, 'CONJ^PREPOSITION^DEF^NNP': 169, 'DEF^BN': 170, 'CONJ^RB': 171, 'TEMP^NN': 172, 'RB': 173, 'PREPOSITION^DEF^RB': 174, 'yyDASH': 175, 'CD': 176, 'PREPOSITION^BNT': 177, 'DEF^PRP': 178, 'PREPOSITION^POS': 179, 'PREPOSITION^yyQUOT^NNP': 180, 'ZVL^RB': 181, 'AT': 182, 'TEMP^PREPOSITION^DEF^NN': 183, 'DEF^NN': 184, 'CONJ^PREPOSITION^BN': 185, 'REL^IN^S_PRN': 186, 'REL^PREPOSITION^DTT': 187, 'CONJ^JJT': 188, 'PREPOSITION^CC': 189, 'CONJ^JJ': 190, 'INTJ': 191, 'REL^yyQUOT^PRP': 192, 'CONJ^TEMP^RB': 193, 'QW': 194, 'CONJ^yyQUOT^NN': 195, 'DEF^DTT': 196, 'TEMP^NNT': 197, 'CONJ^yyQUOT^VB': 198, 'CONJ^REL^COP': 199, 'yyDOT': 200, 'CONJ^QW': 201, 'CONJ^DEF^NN': 202, 'ADVERB^NN': 203, 'PREPOSITION^RB': 204, 'REL^yyQUOT^BN': 205, 'PREPOSITION^PREPOSITION^DEF^DEF': 206, 'JJ': 207, 'PREPOSITION^ PREPOSITION^DEF^NN': 208, 'TEMP^PREPOSITION^NNP': 209, 'yyQM': 210, 'yyCLN': 211, 'CONJ^AT': 212, 'CONJ^yyQUOT^NNT': 213, 'VB^AT^S_PRN': 214, 'REL^PREPOSITION^CDT': 215, 'DT': 216, 'CONJ^DEF^DTT': 217, 'PREPOSITION^CD': 218, 'ZVL^DEF^NNT': 219, 'CONJ^PREPOSITION^CD': 220, 'IN^RB^CD': 221, 'IN^NNP': 222, 'NNT': 223, 'IN^JJT': 224, 'CONJ^TEMP^VB': 225, 'PREPOSITION^DEF^NNT': 226, 'IN^VB': 227, 'CONJ^PREPOSITION^RB': 228, 'REL^ADVERB^CD': 229, 'VB^AT^PRP': 230, 'CONJ^yyQUOT^DEF^NN': 231, 'REL^QW': 232, 'ADVERB^NCD': 233, 'REL^yyQUOT^JJ': 234, 'PREPOSITION^yyQUOT^PREPOSITION^DEF^NN': 235, 'CONJ^PREPOSITION^NNP': 236, 'yyRRB': 237, 'REL^PREPOSITION^NN': 238, 'REL^DEF^NNP': 239, 'CONJ^P': 240, 'CONJ': 241, 'CONJ^BN': 242, 'PREPOSITION^yyQUOT^BN': 243, 'CONJ^PREPOSITION^DTT': 244, 'REL^DEF^JJ': 245, 'PREPOSITION^IN^DEF^PRP': 246, 'PREPOSITION^DEF^JJ': 247, 'CONJ^CDT': 248, 'PREPOSITION^yyQUOT^NN': 249, 'CONJ^PREPOSITION^DEF^NN': 250, 'IN^NN': 251, 'BN': 252, 'AT^PRP': 253, 'NN^yyDOT': 254, 'CONJ^PREPOSITION^yyQUOT^NNP': 255, 'REL^PREPOSITION^DEF^PRP': 256, 'REL^yyQUOT^PREPOSITION^NN': 257, 'DEF^yyQUOT^NN': 258, 'CONJ^REL^NN': 259, 'ZVL^COP': 260, 'IN^RB': 261, 'CONJ^DEF^CD': 262, 'ZVL': 263, 'REL^EX': 264, 'PREPOSITION^RB^S_PRN': 265, 'PREPOSITION^NEG': 266, 'PREPOSITION^NN': 267, 'AT^S_PRN': 268, 'VB^AT^S_ANP': 269, 'TEMP^BN': 270, 'CONJ^VB': 271, 'CONJ^REL^BN': 272, 'PREPOSITION^DEF^NN': 273, 'CONJ^DEF^MD': 274, 'yyCM': 275, 'CONJ^PREPOSITION^DEF^JJ': 276, 'CONJ^NN': 277, 'DEF': 278, 'REL^AT^S_PRN': 279, 'IN^yyQUOT^VB': 280, 'PREPOSITION^DEF^P': 281, 'REL^yyQUOT^NNP': 282, 'DEF^NNT': 283, 'CONJ^IN^DEF^NN': 284, 'REL': 285, 'DEF^yyQUOT^NNP': 286, 'P': 287, 'PREPOSITION^JJT': 288, 'PREPOSITION^VB': 289, 'CONJ^PRP': 290, 'REL^PRP': 291, 'REL^yyQUOT^NN': 292, 'DTT': 293, 'IN^CDT': 294, 'DEF^MD': 295, 'PREPOSITION^DEF': 296, 'CONJ^NNT': 297, 'PREPOSITIONIN^NN': 298, 'REL^yyQUOT^RB': 299, 'CONJ^INTJ': 300, 'DEF^NCD': 301, 'CONJ^EX': 302, 'ZVL^PREPOSITION^NNT': 303, 'CONJ^BNT': 304, 'CONJ^yyQUOT^DEF^JJ': 305, 'PREPOSITION^ADVERB^CDT': 306, 'CONJ^IN^NNT': 307, 'REL^DEF^NN': 308, 'CONJ^IN^PRP': 309, 'CONJ^REL^NNT': 310, 'REL^BN': 311, 'ZVL^NNT': 312, 'REL^VB^AT^PRP': 313, 'DEF^RB': 314}\n",
      "315\n"
     ]
    }
   ],
   "source": [
    "data = train_df\n",
    "tag_vals = list(set(data[\"upostag\"].values))\n",
    "tags = ['PAD'] + tag_vals\n",
    "tag2idx = {tag:idx for idx, tag in enumerate(tags)}\n",
    "idx2tag = {idx:tag for idx, tag in enumerate(tags)}\n",
    "\n",
    "print(tag2idx)\n",
    "# print(idx2tag)\n",
    "print(len(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sentences_and_labels(tokenized_texts, labels):\n",
    "    input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
    "                              maxlen = MAX_LEN, dtype = \"float32\", truncating = \"post\", padding = \"post\", value = tag2idx['PAD'])\n",
    "    tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels], \n",
    "                         maxlen = MAX_LEN, value = tag2idx['PAD'], padding = \"post\",\n",
    "                        dtype = \"float32\", truncating = \"post\")\n",
    "    attention_masks = [[float(i>0) for i in ii] for ii in input_ids]\n",
    "    return input_ids, tags, attention_masks\n",
    "\n",
    "input_ids, tags, attention_masks = pad_sentences_and_labels(train_tokenized_texts, train_tokenized_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_inputs = torch.tensor(input_ids, dtype=torch.long)\n",
    "tr_tags = torch.tensor(tags, dtype=torch.long)\n",
    "tr_masks = torch.tensor(attention_masks, dtype=torch.long)\n",
    "\n",
    "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler = train_sampler, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch:   7%|▋         | 1/15 [01:07<15:45, 67.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 2.2636522917371047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  13%|█▎        | 2/15 [02:16<14:45, 68.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.824631795679268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|██        | 3/15 [03:26<13:44, 68.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.5431916364713719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  27%|██▋       | 4/15 [04:37<12:40, 69.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.4048504241203007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|███▎      | 5/15 [05:47<11:35, 69.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.3150181154671468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|████      | 6/15 [06:58<10:28, 69.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.25438132048829604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  47%|████▋     | 7/15 [08:08<09:19, 69.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.21042053573029607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  53%|█████▎    | 8/15 [09:18<08:10, 70.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.17720720353291222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|██████    | 9/15 [10:29<07:00, 70.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.15340553851504074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████▋   | 10/15 [11:39<05:51, 70.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.1315599238794101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  73%|███████▎  | 11/15 [12:49<04:41, 70.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.1165582447949993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████  | 12/15 [14:00<03:30, 70.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.10681234140831389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  87%|████████▋ | 13/15 [15:10<02:20, 70.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.09523173590729896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  93%|█████████▎| 14/15 [16:20<01:10, 70.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.09027743410613191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 15/15 [17:31<00:00, 70.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.08424550275269307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "model = BertForTokenClassification.from_pretrained('bert-base-multilingual-cased',\n",
    "                                                   num_labels=len(tag2idx),\n",
    "                                                   output_attentions = False,\n",
    "                                                   output_hidden_states = False)\n",
    "model.cuda()\n",
    "FULL_FINETUNING = True\n",
    "if FULL_FINETUNING:\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "else:\n",
    "    param_optimizer = list(model.classifier.named_parameters())\n",
    "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5, eps=1e-8)\n",
    "\n",
    "from seqeval.metrics import f1_score\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=2).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "#     print (pred_flat, labels_flat)\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "epochs = 15\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=total_steps)\n",
    "\n",
    "## Store the average loss after each epoch so we can plot them.\n",
    "loss_values, validation_loss_values = [], []\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "    # TRAIN loop\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # add batch to gpu\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        model.zero_grad()\n",
    "        # forward pass\n",
    "        outputs = model(b_input_ids, token_type_ids=None,\n",
    "                     attention_mask=b_input_mask, labels=b_labels)\n",
    "        # get the loss\n",
    "        loss = outputs[0]\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "        # track train loss\n",
    "        total_loss += loss.item() \n",
    "        # Clip the norm of the gradient\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "        \n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(\"Average train loss: {}\".format(avg_train_loss))\n",
    "    \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function receives a sentence with its labels, and the tokenized sentence and labels\n",
    "def aggr_toks_labels_tags(orig_words, orig_labels, tok_wordps, tok_labels, predicted_tags):\n",
    "    \n",
    "    joint_tokens = []\n",
    "    joint_labels = []\n",
    "    joint_predicted = []\n",
    "#     joint_test = []\n",
    "    \n",
    "    for word in orig_words:\n",
    "        aggregated_tokenized = \"\"\n",
    "        aggregated_label = \"\"\n",
    "        aggregated_predicted = \"\"\n",
    "        aggregated_test = \"\"\n",
    "        \n",
    "        while aggregated_tokenized != word:\n",
    "#             print(len(tok_sent))\n",
    "            tmpTok = tok_wordps.pop(0)\n",
    "#             print(tmpTok)\n",
    "#             print(joint_tokens)\n",
    "            if tmpTok.startswith(\"##\"):\n",
    "                tmpTok = tmpTok[2:]\n",
    "                \n",
    "            tmpLab = tok_labels.pop(0)\n",
    "#             if aggregated_label == \"\":\n",
    "            aggregated_label += '^'\n",
    "            aggregated_label += tmpLab\n",
    "\n",
    "                \n",
    "            tmpPred = predicted_tags.pop(0)\n",
    "#             print(tmpPred)\n",
    "\n",
    "            aggregated_predicted += '^'\n",
    "            aggregated_predicted += tmpPred\n",
    "#             if aggregated_predicted == \"\":\n",
    "#                 aggregated_predicted = tmpPred\n",
    "                \n",
    "#             tmpTest = test_tags.pop(0)\n",
    "#             if aggregated_test == \"\":\n",
    "#                 aggregated_test = tmpTest\n",
    "                \n",
    "            aggregated_tokenized += tmpTok\n",
    "#             print(aggregated_tokenized)\n",
    "            \n",
    "        joint_tokens.append(aggregated_tokenized)\n",
    "        joint_labels.append(aggregated_label)\n",
    "        joint_predicted.append(aggregated_predicted)\n",
    "#         joint_test.append(aggregated_test)\n",
    "        \n",
    "    assert len(joint_tokens) == len(orig_words)\n",
    "    assert len(joint_tokens) == len(joint_predicted)\n",
    "    return joint_tokens, joint_labels, joint_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=2).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "def delete_pads_from_preds(predicted_tags, test_tags):\n",
    "    clean_predicted = []\n",
    "    clean_test = []\n",
    "    \n",
    "    for ix in range(0, len(test_tags)):\n",
    "        if test_tags[ix] != 'PAD':\n",
    "            clean_predicted.append(predicted_tags[ix])\n",
    "            clean_test.append(test_tags[ix])\n",
    "            \n",
    "    return clean_predicted, clean_test\n",
    "    \n",
    "def calculate_accuracy(df):\n",
    "    numOfCorrectPredictions = 0\n",
    "    for index in df.index:\n",
    "        orig_pos = df.at[index, 'orig_label'].strip('^')\n",
    "        pred_pos = df.at[index, 'predicted_tag'].strip('^')\n",
    "        if orig_pos == pred_pos:\n",
    "            numOfCorrectPredictions += 1\n",
    "    return numOfCorrectPredictions/len(df)\n",
    "                \n",
    "def test_model(sentence, labels, tok_sent, tok_labels, corres_tokens, sent_id):\n",
    "    input_ids, tags, attention_masks = pad_sentences_and_labels([tok_sent], [tok_labels])\n",
    "\n",
    "    val_inputs = torch.tensor(input_ids, dtype=torch.long)\n",
    "    val_tags = torch.tensor(tags, dtype=torch.long)\n",
    "    val_masks = torch.tensor(attention_masks, dtype=torch.long)\n",
    "\n",
    "    test_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
    "    test_sampler = SequentialSampler(test_data)\n",
    "    test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=bs)\n",
    "\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    predictions, true_labels = [], []\n",
    "    counter = 0\n",
    "    for batch in test_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids, token_type_ids=None,\n",
    "                                attention_mask=b_input_mask, labels=b_labels)\n",
    "        logits = outputs[1].detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        predictions.append([list(p) for p in np.argmax(logits, axis=2)])\n",
    "        \n",
    "        true_labels.append(label_ids)\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "\n",
    "        eval_loss += outputs[0].mean().item()\n",
    "        eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "        nb_eval_examples += b_input_ids.size(0)\n",
    "        nb_eval_steps += 1\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    \n",
    "    pred_tags = [idx2tag[p_ii] for p in predictions for p_i in p for p_ii in p_i]\n",
    "    joint_tokenized, joint_labels, preds = aggr_toks_labels_tags(sentence, labels, tok_sent, tok_labels, \n",
    "                                                                        pred_tags)\n",
    "    \n",
    "    tmp = {'word': sentence, 'orig_label': labels, 'predicted_tag': preds, \n",
    "           'corresToken': corres_tokens, 'sent_id': sent_id}\n",
    "    tmp_df = pd.DataFrame(data=tmp)\n",
    "    return tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (F1): = 0.46167773083886543\n"
     ]
    }
   ],
   "source": [
    "full_dev_df = pd.DataFrame()\n",
    "dev_tokenized_texts, dev_tokenized_labels = tokenize(dev_sentences, dev_labels)\n",
    "for sent, label, tok_sent, tok_label, corresTokens, sent_id in zip(dev_sentences, dev_labels, dev_tokenized_texts, \n",
    "                                                                   dev_tokenized_labels, dev_corresTokens, \n",
    "                                                                   dev_sent_ids):\n",
    "    eval_df = test_model(sent, label, tok_sent, tok_label, corresTokens, sent_id)\n",
    "    full_dev_df = full_dev_df.append(eval_df, ignore_index=True, sort=False)\n",
    "\n",
    "# full_df\n",
    "f1_accuracy = calculate_accuracy(full_dev_df)\n",
    "print(\"Accuracy (F1): = {}\".format(f1_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>orig_label</th>\n",
       "      <th>predicted_tag</th>\n",
       "      <th>corresToken</th>\n",
       "      <th>sent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>עשרות</td>\n",
       "      <td>CDT</td>\n",
       "      <td>^CD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>אנשים</td>\n",
       "      <td>NN</td>\n",
       "      <td>^NN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>מגיעים</td>\n",
       "      <td>BN</td>\n",
       "      <td>^BN^BN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>PREPOSITION^NNP</td>\n",
       "      <td>^PREPOSITION^NNP^PREPOSITION^NNP^PREPOSITION^NNP</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>לישראל</td>\n",
       "      <td>PREPOSITION^NNP</td>\n",
       "      <td>^PREPOSITION^NNP</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word       orig_label                                     predicted_tag  \\\n",
       "0    עשרות              CDT                                               ^CD   \n",
       "1    אנשים               NN                                               ^NN   \n",
       "2   מגיעים               BN                                            ^BN^BN   \n",
       "3  מתאילנד  PREPOSITION^NNP  ^PREPOSITION^NNP^PREPOSITION^NNP^PREPOSITION^NNP   \n",
       "4   לישראל  PREPOSITION^NNP                                  ^PREPOSITION^NNP   \n",
       "\n",
       "   corresToken  sent_id  \n",
       "0            1        1  \n",
       "1            2        1  \n",
       "2            3        1  \n",
       "3            4        1  \n",
       "4            5        1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (F1): = 0.4518057880889739\n"
     ]
    }
   ],
   "source": [
    "full_test_df = pd.DataFrame()\n",
    "test_tokenized_texts, test_tokenized_labels = tokenize(test_sentences, test_labels)\n",
    "for sent, label, tok_sent, tok_label, corresTokens, sent_id in zip(test_sentences, test_labels, test_tokenized_texts, \n",
    "                                                                   test_tokenized_labels, test_corresTokens, \n",
    "                                                                   test_sent_ids):\n",
    "    eval_df = test_model(sent, label, tok_sent, tok_label, corresTokens, sent_id)\n",
    "    full_test_df = full_test_df.append(eval_df, ignore_index=True, sort=False)\n",
    "\n",
    "# full_df\n",
    "f1_accuracy = calculate_accuracy(full_test_df)\n",
    "print(\"Accuracy (F1): = {}\".format(f1_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>orig_label</th>\n",
       "      <th>predicted_tag</th>\n",
       "      <th>corresToken</th>\n",
       "      <th>sent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8255</th>\n",
       "      <td>קדישא</td>\n",
       "      <td>NNP</td>\n",
       "      <td>^NNP^RB^RB</td>\n",
       "      <td>7</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8256</th>\n",
       "      <td>ורק</td>\n",
       "      <td>CONJ^RB</td>\n",
       "      <td>^CONJ^RB</td>\n",
       "      <td>8</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8257</th>\n",
       "      <td>תוך</td>\n",
       "      <td>IN</td>\n",
       "      <td>^IN</td>\n",
       "      <td>9</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8258</th>\n",
       "      <td>דחיפות</td>\n",
       "      <td>NN</td>\n",
       "      <td>^NN^NN^NN</td>\n",
       "      <td>10</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8259</th>\n",
       "      <td>וצעקות</td>\n",
       "      <td>CONJ^NN</td>\n",
       "      <td>^CONJ^NN^CONJ^NN^CONJ^NN</td>\n",
       "      <td>11</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8260</th>\n",
       "      <td>הורדה</td>\n",
       "      <td>VB</td>\n",
       "      <td>^VB^VB^VB</td>\n",
       "      <td>12</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8261</th>\n",
       "      <td>גופתו</td>\n",
       "      <td>NN</td>\n",
       "      <td>^NN^NN^NN</td>\n",
       "      <td>13</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8262</th>\n",
       "      <td>של</td>\n",
       "      <td>POS</td>\n",
       "      <td>^POS</td>\n",
       "      <td>14</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8263</th>\n",
       "      <td>מאיר</td>\n",
       "      <td>NNP</td>\n",
       "      <td>^NNP</td>\n",
       "      <td>15</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8264</th>\n",
       "      <td>כהנא</td>\n",
       "      <td>NNP</td>\n",
       "      <td>^NNP^NNP^NNP</td>\n",
       "      <td>16</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8265</th>\n",
       "      <td>אל</td>\n",
       "      <td>IN</td>\n",
       "      <td>^IN</td>\n",
       "      <td>17</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8266</th>\n",
       "      <td>הקבר</td>\n",
       "      <td>DEF^NN</td>\n",
       "      <td>^DEF^NN^DEF^NN^DEF^NN</td>\n",
       "      <td>18</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8267</th>\n",
       "      <td>.</td>\n",
       "      <td>yyDOT</td>\n",
       "      <td>^yyDOT</td>\n",
       "      <td>19</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8268</th>\n",
       "      <td>עכשיו</td>\n",
       "      <td>RB</td>\n",
       "      <td>^RB^RB^RB^RB</td>\n",
       "      <td>1</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8269</th>\n",
       "      <td>קוראים</td>\n",
       "      <td>BN</td>\n",
       "      <td>^BN^BN^BN</td>\n",
       "      <td>2</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8270</th>\n",
       "      <td>את</td>\n",
       "      <td>AT</td>\n",
       "      <td>^AT</td>\n",
       "      <td>3</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8271</th>\n",
       "      <td>הקדיש</td>\n",
       "      <td>DEF^NN</td>\n",
       "      <td>^DEF^NN^DEF^NN^DEF^NN</td>\n",
       "      <td>4</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8272</th>\n",
       "      <td>,</td>\n",
       "      <td>yyCM</td>\n",
       "      <td>^yyCM</td>\n",
       "      <td>5</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8273</th>\n",
       "      <td>והקהל</td>\n",
       "      <td>CONJ^DEF^NN</td>\n",
       "      <td>^CONJ^DEF^NN^CONJ^DEF^NN^CONJ^DEF^NN</td>\n",
       "      <td>6</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8274</th>\n",
       "      <td>עונה</td>\n",
       "      <td>BN</td>\n",
       "      <td>^BN</td>\n",
       "      <td>7</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8275</th>\n",
       "      <td>אמן</td>\n",
       "      <td>NN</td>\n",
       "      <td>^NN^NN</td>\n",
       "      <td>8</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8276</th>\n",
       "      <td>.</td>\n",
       "      <td>yyDOT</td>\n",
       "      <td>^yyDOT</td>\n",
       "      <td>9</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8277</th>\n",
       "      <td>תם</td>\n",
       "      <td>VB</td>\n",
       "      <td>^RB^RB</td>\n",
       "      <td>1</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8278</th>\n",
       "      <td>מסע</td>\n",
       "      <td>NNT</td>\n",
       "      <td>^NNT</td>\n",
       "      <td>2</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8279</th>\n",
       "      <td>ההלווייה</td>\n",
       "      <td>DEF^NN</td>\n",
       "      <td>^DEF^NN^DEF^NN^DEF^NN^DEF^NN</td>\n",
       "      <td>3</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8280</th>\n",
       "      <td>.</td>\n",
       "      <td>yyDOT</td>\n",
       "      <td>^yyDOT</td>\n",
       "      <td>4</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8281</th>\n",
       "      <td>מתחיל</td>\n",
       "      <td>BN</td>\n",
       "      <td>^BN^BN</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8282</th>\n",
       "      <td>מסע</td>\n",
       "      <td>NNT</td>\n",
       "      <td>^NNT</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8283</th>\n",
       "      <td>הנקמה</td>\n",
       "      <td>DEF^NN</td>\n",
       "      <td>^DEF^NN^DEF^NN^DEF^NN</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8284</th>\n",
       "      <td>.</td>\n",
       "      <td>yyDOT</td>\n",
       "      <td>^yyDOT</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word   orig_label                         predicted_tag  \\\n",
       "8255     קדישא          NNP                            ^NNP^RB^RB   \n",
       "8256       ורק      CONJ^RB                              ^CONJ^RB   \n",
       "8257       תוך           IN                                   ^IN   \n",
       "8258    דחיפות           NN                             ^NN^NN^NN   \n",
       "8259    וצעקות      CONJ^NN              ^CONJ^NN^CONJ^NN^CONJ^NN   \n",
       "8260     הורדה           VB                             ^VB^VB^VB   \n",
       "8261     גופתו           NN                             ^NN^NN^NN   \n",
       "8262        של          POS                                  ^POS   \n",
       "8263      מאיר          NNP                                  ^NNP   \n",
       "8264      כהנא          NNP                          ^NNP^NNP^NNP   \n",
       "8265        אל           IN                                   ^IN   \n",
       "8266      הקבר       DEF^NN                 ^DEF^NN^DEF^NN^DEF^NN   \n",
       "8267         .        yyDOT                                ^yyDOT   \n",
       "8268     עכשיו           RB                          ^RB^RB^RB^RB   \n",
       "8269    קוראים           BN                             ^BN^BN^BN   \n",
       "8270        את           AT                                   ^AT   \n",
       "8271     הקדיש       DEF^NN                 ^DEF^NN^DEF^NN^DEF^NN   \n",
       "8272         ,         yyCM                                 ^yyCM   \n",
       "8273     והקהל  CONJ^DEF^NN  ^CONJ^DEF^NN^CONJ^DEF^NN^CONJ^DEF^NN   \n",
       "8274      עונה           BN                                   ^BN   \n",
       "8275       אמן           NN                                ^NN^NN   \n",
       "8276         .        yyDOT                                ^yyDOT   \n",
       "8277        תם           VB                                ^RB^RB   \n",
       "8278       מסע          NNT                                  ^NNT   \n",
       "8279  ההלווייה       DEF^NN          ^DEF^NN^DEF^NN^DEF^NN^DEF^NN   \n",
       "8280         .        yyDOT                                ^yyDOT   \n",
       "8281     מתחיל           BN                                ^BN^BN   \n",
       "8282       מסע          NNT                                  ^NNT   \n",
       "8283     הנקמה       DEF^NN                 ^DEF^NN^DEF^NN^DEF^NN   \n",
       "8284         .        yyDOT                                ^yyDOT   \n",
       "\n",
       "      corresToken  sent_id  \n",
       "8255            7      497  \n",
       "8256            8      497  \n",
       "8257            9      497  \n",
       "8258           10      497  \n",
       "8259           11      497  \n",
       "8260           12      497  \n",
       "8261           13      497  \n",
       "8262           14      497  \n",
       "8263           15      497  \n",
       "8264           16      497  \n",
       "8265           17      497  \n",
       "8266           18      497  \n",
       "8267           19      497  \n",
       "8268            1      498  \n",
       "8269            2      498  \n",
       "8270            3      498  \n",
       "8271            4      498  \n",
       "8272            5      498  \n",
       "8273            6      498  \n",
       "8274            7      498  \n",
       "8275            8      498  \n",
       "8276            9      498  \n",
       "8277            1      499  \n",
       "8278            2      499  \n",
       "8279            3      499  \n",
       "8280            4      499  \n",
       "8281            1      500  \n",
       "8282            2      500  \n",
       "8283            3      500  \n",
       "8284            4      500  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dev_df.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For evaluating on gold-dev/gold-test only - regrouping the tokens to words\n",
    "dev_predicted = full_dev_df.groupby(['sent_id', 'corresToken']).apply(lambda x: '^'.join(x.predicted_tag)).reset_index()\n",
    "dev_original = full_dev_df.groupby(['sent_id', 'corresToken']).apply(lambda x: '^'.join(x.orig_label)).reset_index()\n",
    "dev_combined = pd.merge(dev_original, dev_predicted, on=['sent_id', 'corresToken'])\n",
    "dev_combined.rename(columns = {\"0_x\": \"orig_label\", \"0_y\":\"predicted_tag\"}, inplace = True)\n",
    "\n",
    "test_predicted = full_test_df.groupby(['sent_id', 'corresToken']).apply(lambda x: '^'.join(x.predicted_tag)).reset_index()\n",
    "test_original = full_test_df.groupby(['sent_id', 'corresToken']).apply(lambda x: '^'.join(x.orig_label)).reset_index()\n",
    "test_combined = pd.merge(test_original, test_predicted, on=['sent_id', 'corresToken'])\n",
    "test_combined.rename(columns = {\"0_x\": \"orig_label\", \"0_y\":\"predicted_tag\"}, inplace = True)\n",
    "# word_acc_test = full_test_df.groupby(['sent_id', 'corresToken']).apply(lambda x: '^'.join(x.predicted_tag)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>corresToken</th>\n",
       "      <th>orig_label</th>\n",
       "      <th>predicted_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CDT</td>\n",
       "      <td>^CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NN</td>\n",
       "      <td>^NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>BN</td>\n",
       "      <td>^BN^BN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>PREPOSITION^NNP</td>\n",
       "      <td>^PREPOSITION^NNP^PREPOSITION^NNP^PREPOSITION^NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>PREPOSITION^NNP</td>\n",
       "      <td>^PREPOSITION^NNP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sent_id  corresToken       orig_label  \\\n",
       "0        1            1              CDT   \n",
       "1        1            2               NN   \n",
       "2        1            3               BN   \n",
       "3        1            4  PREPOSITION^NNP   \n",
       "4        1            5  PREPOSITION^NNP   \n",
       "\n",
       "                                      predicted_tag  \n",
       "0                                               ^CD  \n",
       "1                                               ^NN  \n",
       "2                                            ^BN^BN  \n",
       "3  ^PREPOSITION^NNP^PREPOSITION^NNP^PREPOSITION^NNP  \n",
       "4                                  ^PREPOSITION^NNP  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_combined.to_csv('ftRaw_evalGoldDev_whole_pos_shuffle.csv')\n",
    "test_combined.to_csv('ftRaw_evalGoldTest_whole_pos_shuffle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from more_itertools import unique_everseen\n",
    "\n",
    "def unique_vals_to_list(df):\n",
    "    for index in df.index:\n",
    "        joint_pred = df.at[index, 'predicted_tag']\n",
    "        joint_orig = df.at[index, 'orig_label']\n",
    "        \n",
    "        predicted_tag_list = joint_pred.split('^')\n",
    "        predicted_tag_list_no_empty = list(filter(None, predicted_tag_list))\n",
    "        original_tag_list = joint_orig.split('^')\n",
    "        original_tag_list_no_empty = list(filter(None, original_tag_list))\n",
    "\n",
    "        \n",
    "        df.at[index, 'predicted_tag'] = list(unique_everseen(predicted_tag_list_no_empty))\n",
    "        df.at[index, 'orig_label'] = list(unique_everseen(original_tag_list_no_empty))\n",
    "        \n",
    "        \n",
    "unique_vals_to_list(full_dev_df)\n",
    "unique_vals_to_list(full_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>corresToken</th>\n",
       "      <th>orig_label</th>\n",
       "      <th>predicted_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8255</th>\n",
       "      <td>497</td>\n",
       "      <td>7</td>\n",
       "      <td>NNP</td>\n",
       "      <td>^NNP^RB^RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8256</th>\n",
       "      <td>497</td>\n",
       "      <td>8</td>\n",
       "      <td>CONJ^RB</td>\n",
       "      <td>^CONJ^RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8257</th>\n",
       "      <td>497</td>\n",
       "      <td>9</td>\n",
       "      <td>IN</td>\n",
       "      <td>^IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8258</th>\n",
       "      <td>497</td>\n",
       "      <td>10</td>\n",
       "      <td>NN</td>\n",
       "      <td>^NN^NN^NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8259</th>\n",
       "      <td>497</td>\n",
       "      <td>11</td>\n",
       "      <td>CONJ^NN</td>\n",
       "      <td>^CONJ^NN^CONJ^NN^CONJ^NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8260</th>\n",
       "      <td>497</td>\n",
       "      <td>12</td>\n",
       "      <td>VB</td>\n",
       "      <td>^VB^VB^VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8261</th>\n",
       "      <td>497</td>\n",
       "      <td>13</td>\n",
       "      <td>NN</td>\n",
       "      <td>^NN^NN^NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8262</th>\n",
       "      <td>497</td>\n",
       "      <td>14</td>\n",
       "      <td>POS</td>\n",
       "      <td>^POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8263</th>\n",
       "      <td>497</td>\n",
       "      <td>15</td>\n",
       "      <td>NNP</td>\n",
       "      <td>^NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8264</th>\n",
       "      <td>497</td>\n",
       "      <td>16</td>\n",
       "      <td>NNP</td>\n",
       "      <td>^NNP^NNP^NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8265</th>\n",
       "      <td>497</td>\n",
       "      <td>17</td>\n",
       "      <td>IN</td>\n",
       "      <td>^IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8266</th>\n",
       "      <td>497</td>\n",
       "      <td>18</td>\n",
       "      <td>DEF^NN</td>\n",
       "      <td>^DEF^NN^DEF^NN^DEF^NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8267</th>\n",
       "      <td>497</td>\n",
       "      <td>19</td>\n",
       "      <td>yyDOT</td>\n",
       "      <td>^yyDOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8268</th>\n",
       "      <td>498</td>\n",
       "      <td>1</td>\n",
       "      <td>RB</td>\n",
       "      <td>^RB^RB^RB^RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8269</th>\n",
       "      <td>498</td>\n",
       "      <td>2</td>\n",
       "      <td>BN</td>\n",
       "      <td>^BN^BN^BN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8270</th>\n",
       "      <td>498</td>\n",
       "      <td>3</td>\n",
       "      <td>AT</td>\n",
       "      <td>^AT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8271</th>\n",
       "      <td>498</td>\n",
       "      <td>4</td>\n",
       "      <td>DEF^NN</td>\n",
       "      <td>^DEF^NN^DEF^NN^DEF^NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8272</th>\n",
       "      <td>498</td>\n",
       "      <td>5</td>\n",
       "      <td>yyCM</td>\n",
       "      <td>^yyCM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8273</th>\n",
       "      <td>498</td>\n",
       "      <td>6</td>\n",
       "      <td>CONJ^DEF^NN</td>\n",
       "      <td>^CONJ^DEF^NN^CONJ^DEF^NN^CONJ^DEF^NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8274</th>\n",
       "      <td>498</td>\n",
       "      <td>7</td>\n",
       "      <td>BN</td>\n",
       "      <td>^BN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8275</th>\n",
       "      <td>498</td>\n",
       "      <td>8</td>\n",
       "      <td>NN</td>\n",
       "      <td>^NN^NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8276</th>\n",
       "      <td>498</td>\n",
       "      <td>9</td>\n",
       "      <td>yyDOT</td>\n",
       "      <td>^yyDOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8277</th>\n",
       "      <td>499</td>\n",
       "      <td>1</td>\n",
       "      <td>VB</td>\n",
       "      <td>^RB^RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8278</th>\n",
       "      <td>499</td>\n",
       "      <td>2</td>\n",
       "      <td>NNT</td>\n",
       "      <td>^NNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8279</th>\n",
       "      <td>499</td>\n",
       "      <td>3</td>\n",
       "      <td>DEF^NN</td>\n",
       "      <td>^DEF^NN^DEF^NN^DEF^NN^DEF^NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8280</th>\n",
       "      <td>499</td>\n",
       "      <td>4</td>\n",
       "      <td>yyDOT</td>\n",
       "      <td>^yyDOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8281</th>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>BN</td>\n",
       "      <td>^BN^BN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8282</th>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>NNT</td>\n",
       "      <td>^NNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8283</th>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>DEF^NN</td>\n",
       "      <td>^DEF^NN^DEF^NN^DEF^NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8284</th>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>yyDOT</td>\n",
       "      <td>^yyDOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sent_id  corresToken   orig_label                         predicted_tag\n",
       "8255      497            7          NNP                            ^NNP^RB^RB\n",
       "8256      497            8      CONJ^RB                              ^CONJ^RB\n",
       "8257      497            9           IN                                   ^IN\n",
       "8258      497           10           NN                             ^NN^NN^NN\n",
       "8259      497           11      CONJ^NN              ^CONJ^NN^CONJ^NN^CONJ^NN\n",
       "8260      497           12           VB                             ^VB^VB^VB\n",
       "8261      497           13           NN                             ^NN^NN^NN\n",
       "8262      497           14          POS                                  ^POS\n",
       "8263      497           15          NNP                                  ^NNP\n",
       "8264      497           16          NNP                          ^NNP^NNP^NNP\n",
       "8265      497           17           IN                                   ^IN\n",
       "8266      497           18       DEF^NN                 ^DEF^NN^DEF^NN^DEF^NN\n",
       "8267      497           19        yyDOT                                ^yyDOT\n",
       "8268      498            1           RB                          ^RB^RB^RB^RB\n",
       "8269      498            2           BN                             ^BN^BN^BN\n",
       "8270      498            3           AT                                   ^AT\n",
       "8271      498            4       DEF^NN                 ^DEF^NN^DEF^NN^DEF^NN\n",
       "8272      498            5         yyCM                                 ^yyCM\n",
       "8273      498            6  CONJ^DEF^NN  ^CONJ^DEF^NN^CONJ^DEF^NN^CONJ^DEF^NN\n",
       "8274      498            7           BN                                   ^BN\n",
       "8275      498            8           NN                                ^NN^NN\n",
       "8276      498            9        yyDOT                                ^yyDOT\n",
       "8277      499            1           VB                                ^RB^RB\n",
       "8278      499            2          NNT                                  ^NNT\n",
       "8279      499            3       DEF^NN          ^DEF^NN^DEF^NN^DEF^NN^DEF^NN\n",
       "8280      499            4        yyDOT                                ^yyDOT\n",
       "8281      500            1           BN                                ^BN^BN\n",
       "8282      500            2          NNT                                  ^NNT\n",
       "8283      500            3       DEF^NN                 ^DEF^NN^DEF^NN^DEF^NN\n",
       "8284      500            4        yyDOT                                ^yyDOT"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_combined.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV - Exact Match Accuracy = 46.17%\n",
      "TEST - Exact Match Accuracy = 45.18%\n"
     ]
    }
   ],
   "source": [
    "def exact_match_accuracy(df):\n",
    "    exact_matches = 0\n",
    "    for index in df.index:\n",
    "        if df.at[index, 'orig_label'] == df.at[index, 'predicted_tag'].strip('^'):\n",
    "            exact_matches += 1\n",
    "            \n",
    "    return exact_matches\n",
    "\n",
    "print(\"DEV - Exact Match Accuracy = {0:.2f}%\".format(exact_match_accuracy(dev_combined)/len(dev_combined) * 100))\n",
    "print(\"TEST - Exact Match Accuracy = {0:.2f}%\".format(exact_match_accuracy(test_combined)/len(test_combined) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV:\n",
      "Precision: 29.69%\n",
      "Recall: 71.44%\n",
      "F1: 41.95%\n",
      "TEST:\n",
      "Precision: 29.24%\n",
      "Recall: 71.56%\n",
      "F1: 41.52%\n"
     ]
    }
   ],
   "source": [
    "def existence_accuracy(df):\n",
    "    # correct tag = appeared in predicted and in gold\n",
    "    total_orig_num_of_labels = 0\n",
    "    total_predicted_num_of_labels = 0\n",
    "    total_num_of_correct_tags = 0\n",
    "    \n",
    "    for index in df.index:\n",
    "        orig_list = df.at[index, 'orig_label']\n",
    "        predicted_list = df.at[index, 'predicted_tag'].strip('^')\n",
    "        total_orig_num_of_labels += len(orig_list)\n",
    "        total_predicted_num_of_labels += len(predicted_list)\n",
    "        total_num_of_correct_tags += len(set(orig_list).intersection(set(predicted_list)))\n",
    "        \n",
    "    precision = total_num_of_correct_tags / total_predicted_num_of_labels * 100\n",
    "    recall = total_num_of_correct_tags / total_orig_num_of_labels * 100\n",
    "    f1 = 2*precision*recall/(precision+recall)\n",
    "    \n",
    "    print(\"Precision: {0:.2f}%\".format(precision))\n",
    "    print(\"Recall: {0:.2f}%\".format(recall))\n",
    "    print(\"F1: {0:.2f}%\".format(f1))\n",
    "    \n",
    "print(\"DEV:\")\n",
    "existence_accuracy(dev_combined)\n",
    "print(\"TEST:\")\n",
    "existence_accuracy(test_combined)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
